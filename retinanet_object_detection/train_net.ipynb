{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Filename:**        train_net.ipynb <br/>\n",
    "**Project name:**    Real-time applications of Computer Vision on UAVs <br/>\n",
    "**Author:**          Satyam Gaba (satyamgb321@gmail.com) <br/>\n",
    "**Supervisor:**      [Pratik Narang](https://www.bits-pilani.ac.in/pilani/pratiknarang/profile) <br/>\n",
    "**Last modified:**   25 May 2019 <br/>\n",
    "**Comments:**        This file contains the python script to train the neural network on aiskeye dataset for aerial image recognition. <br/>\n",
    "**References:**      [Keras implementation of RetinaNet object detection](https://github.com/fizyr/keras-retinanet), <br/>\n",
    "                     [ESRI Object Detection](https://github.com/kunwar31/ESRI_Object_Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#download and install keras-retinanet library\n",
    "\n",
    "#!git clone https://github.com/fizyr/keras-retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#!pip3 install keras-retinanet/ --user\n",
    "#!pip install jupyter_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb2593dea04ab0e20ef4ee521dd8cba7f3bd987b"
   },
   "outputs": [],
   "source": [
    "#!rm keras-retinanet/ -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "907236db932c74a1170900b8e6d9cc60bd086206"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# to limit TensorFlow to first GPU \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"     \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# to verify the GPU in use\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "907236db932c74a1170900b8e6d9cc60bd086206"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from os import listdir, walk\n",
    "from os.path import join\n",
    "from keras_retinanet.bin.train import create_generators,create_models,create_callbacks\n",
    "from keras_retinanet.models import backbone,load_model,convert_model\n",
    "from keras_retinanet.utils.config import read_config_file,parse_anchor_parameters\n",
    "from keras_retinanet.utils.visualization import draw_boxes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "tf.set_random_seed(31) # SEEDS MAKE RESULTS MORE REPRODUCABLE\n",
    "np.random.seed(17)\n",
    "\n",
    "from keras_retinanet.utils.model import freeze as freeze_model\n",
    "import keras_retinanet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04461e1dd8304d4224c0ce6fe9a1da1040b8aa9d"
   },
   "source": [
    "# Reading Training and Validation data\n",
    "\n",
    "Normally we would have 10-30% of our images in validation set but as we want best possible score we'll use all our images to train, as we have quite few training images already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32f27dd808794bf8659b9e668b0e490bc6a104b7"
   },
   "outputs": [],
   "source": [
    "#training and validation dataset path\n",
    "path_train_dset = '/home/pytorch/satyam/object_detection/dataset/train_final/'\n",
    "path_val_dset = '/home/pytorch/satyam/object_detection/dataset/val_final/'\n",
    "\n",
    "_,_,train_ids = next(walk(path_train_dset))\n",
    "_,_,val_ids = next(walk(path_val_dset))\n",
    "    \n",
    "print(len(train_ids),len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use when images are randomly selected in csv file from each scenario in aiskyeye dataset\n",
    "\n",
    "# train_csv = '/home/pytorch/satyam/object_detection/dataset/train_final/annotations/train_annotations.csv'\n",
    "# val_csv = '/home/pytorch/satyam/object_detection/dataset/val_final/annotations/val_annotations.csv'\n",
    "\n",
    "# '''function will give number of images in the csv'''\n",
    "# def find_num_img(csv_file):\n",
    "#     with open(csv_file, 'r') as csvfile:\n",
    "#             csvreader = csv.reader(csvfile, delimiter = ',', lineterminator = '\\n') \n",
    "#             img_list=[]\n",
    "#             i=0\n",
    "#             for row in csvreader:\n",
    "#                 img_list.append(row[0])\n",
    "#                 i=i+1\n",
    "#             num_ids = len(list(set(img_list))) # number of unique elements in the list\n",
    "#     return num_ids\n",
    "        \n",
    "# len_train_ids = find_num_img(train_csv)\n",
    "# len_val_ids = find_num_img(val_csv)\n",
    "# print(len_train_ids,len_val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "add87f5c791fbe8da4793a384e983235587d1626"
   },
   "source": [
    "# Anchor Parameters\n",
    "\n",
    "1. Anchor parameters are used to decide how anchor boxes will be generated for the model.\n",
    "1. As we're dealing mostly small boxes with can be highly elongated, we'll change ratios and scales to fit our needs.\n",
    "1. test_anchors.ipynb is used to visualize anchors on ground truth boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17398f319e28dd6e38948e2e09dc87481e1966bc"
   },
   "outputs": [],
   "source": [
    "with open('config.ini','w') as f:\n",
    "    f.write('[anchor_parameters]\\nsizes   = 32 64 128 256 512\\nstrides = 8 16 32 64 128\\nratios  = 0.25 0.5 0.75 1 1.5 2 4 6 8 10\\nscales  = 0.5 1 2\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "867d2c56814d761227270459f837b787e616f4c5"
   },
   "source": [
    "# Some Hyperparameters\n",
    "\n",
    "We will rescale our images to 672x672 for better precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab8e28dc982006ee8f8800a9021433f0d716fc48"
   },
   "outputs": [],
   "source": [
    "b = backbone('resnet50')\n",
    "\n",
    "class args:\n",
    "    batch_size = 4\n",
    "    config = read_config_file('config.ini')\n",
    "    random_transform = True # Image augmentation\n",
    "    annotations = '/home/pytorch/satyam/object_detection/dataset/train_final/annotations/train_annotations.csv'\n",
    "    val_annotations = '/home/pytorch/satyam/object_detection/dataset/val_final/annotations/val_annotations.csv'\n",
    "    classes = '/home/pytorch/satyam/object_detection/dataset/train_final/annotations/class_mapping.csv'\n",
    "    image_min_side = 672\n",
    "    image_max_side = 672\n",
    "    dataset_type = 'csv'\n",
    "    tensorboard_dir = ''\n",
    "    evaluation = False\n",
    "    snapshots = True\n",
    "    snapshot_path = \"saved/\"\n",
    "    backbone = 'resnet50'\n",
    "    epochs = 30\n",
    "    steps = len(train_ids)//(batch_size)\n",
    "    weighted_average = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4551ed97d6ee33f91283f559bbb7d9549d2d1f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gen,valid_gen = create_generators(args,b.preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48482aa28034ede1fc5dd69661bbf83163ddb7bd"
   },
   "source": [
    "# Image Augmentation\n",
    "\n",
    "In addition to augmentations already done by keras-retinanet [here](https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/bin/train.py#L227) , we'll use a package called imgaug to furthur augment the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c09f817a02a3c385181a216f1c7c1af993efcf09"
   },
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "# Define our sequence of augmentation steps that will be applied to every image.\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        #\n",
    "        # Execute 1 to 9 of the following (less important) augmenters per\n",
    "        # image. Don't execute all of them, as that would often be way too\n",
    "        # strong.\n",
    "        #\n",
    "        iaa.SomeOf((1, 9),\n",
    "            [\n",
    "\n",
    "                        # Blur each image with varying strength using\n",
    "                        # gaussian blur (sigma between 0 and .5),\n",
    "                        # average/uniform blur (kernel size 1x1)\n",
    "                        # median blur (kernel size 1x1).\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0,0.5)),\n",
    "                            iaa.AverageBlur(k=(1)),\n",
    "                            iaa.MedianBlur(k=(1)),\n",
    "                        ]),\n",
    "\n",
    "                        # Sharpen each image, overlay the result with the original\n",
    "                        # image using an alpha between 0 (no sharpening) and 1\n",
    "                        # (full sharpening effect).\n",
    "                        iaa.Sharpen(alpha=(0, 0.25), lightness=(0.75, 1.5)),\n",
    "\n",
    "                        # Add gaussian noise to some images.\n",
    "                        # In 50% of these cases, the noise is randomly sampled per\n",
    "                        # channel and pixel.\n",
    "                        # In the other 50% of all cases it is sampled once per\n",
    "                        # pixel (i.e. brightness change).\n",
    "                        iaa.AdditiveGaussianNoise(\n",
    "                            loc=0, scale=(0.0, 0.01*255), per_channel=0.5\n",
    "                        ),\n",
    "\n",
    "                        # Either drop randomly 1 to 10% of all pixels (i.e. set\n",
    "                        # them to black) or drop them on an image with 2-5% percent\n",
    "                        # of the original size, leading to large dropped\n",
    "                        # rectangles.\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "                            iaa.CoarseDropout(\n",
    "                                (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                                per_channel=0.2\n",
    "                            ),\n",
    "                        ]),\n",
    "\n",
    "                        # Add a value of -5 to 5 to each pixel.\n",
    "                        iaa.Add((-5, 5), per_channel=0.5),\n",
    "\n",
    "                        # Change brightness of images (85-115% of original value).\n",
    "                        iaa.Multiply((0.85, 1.15), per_channel=0.5),\n",
    "\n",
    "                        # Improve or worsen the contrast of images.\n",
    "                        iaa.ContrastNormalization((0.75, 1.25), per_channel=0.5),\n",
    "\n",
    "                        # Convert each image to grayscale and then overlay the\n",
    "                        # result with the original with random alpha. I.e. remove\n",
    "                        # colors with varying strengths.\n",
    "                        iaa.Grayscale(alpha=(0.0, 0.25)),\n",
    "\n",
    "                        # In some images distort local areas with varying strength.\n",
    "                        sometimes(iaa.PiecewiseAffine(scale=(0.001, 0.01)))\n",
    "                    ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    # do all of the above augmentations in random order\n",
    "    random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2743e4a77f3b2d2e1c702b0c968e07e7603d2cc"
   },
   "outputs": [],
   "source": [
    "def augment_train_gen(train_gen,visualize=False):\n",
    "    '''\n",
    "    Creates a generator using another generator with applied image augmentation.\n",
    "    Args\n",
    "        train_gen  : keras-retinanet generator object.\n",
    "        visualize  : Boolean; False will convert bounding boxes to their anchor box targets for the model.\n",
    "    '''\n",
    "    imgs = []\n",
    "    boxes = []\n",
    "    targets = []\n",
    "    size = train_gen.size()\n",
    "    idx = 0\n",
    "    while True:\n",
    "        while len(imgs) < args.batch_size:\n",
    "            image       = train_gen.load_image(idx % size)\n",
    "            annotations = train_gen.load_annotations(idx % size)\n",
    "            image,annotations = train_gen.random_transform_group_entry(image,annotations)\n",
    "            imgs.append(image)            \n",
    "            boxes.append(annotations['bboxes'])\n",
    "            targets.append(annotations)\n",
    "            idx += 1\n",
    "        if visualize:\n",
    "            imgs = seq.augment_images(imgs)\n",
    "            imgs = np.array(imgs)\n",
    "            boxes = np.array(boxes)\n",
    "            yield imgs,boxes\n",
    "        else:\n",
    "            imgs = seq.augment_images(imgs)\n",
    "            imgs,targets = train_gen.preprocess_group(imgs,targets)\n",
    "            imgs = train_gen.compute_inputs(imgs)\n",
    "            targets = train_gen.compute_targets(imgs,targets)\n",
    "            imgs = np.array(imgs)\n",
    "            yield imgs,targets\n",
    "        imgs = []\n",
    "        boxes = []\n",
    "        targets = []\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "755f6bb05e3251d40877ddba74c8f6486678f47c"
   },
   "source": [
    "# Visualize augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -U pip\n",
    "!python -m pip install -U matplotlib\n",
    "!conda uninstall matplotlib --yes\n",
    "!conda install matplotlib --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcd7d99112b845fe8b42ca980d3842361db93614"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "skip_batches = 4\n",
    "i = 0\n",
    "\n",
    "for imgs,boxes in augment_train_gen(train_gen,visualize=True):\n",
    "    if i > skip_batches:\n",
    "        fig=plt.figure(figsize=(24,96))\n",
    "        columns = 2\n",
    "        rows = 8\n",
    "        for i in range(1, columns*rows + 1):\n",
    "            draw_boxes(imgs[i], boxes[i], (0, 255, 0), thickness=1)\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(cv2.cvtColor(imgs[i],cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35f45954269581be05dbc6a9601965db625609d8"
   },
   "source": [
    "# More Hyperparameters\n",
    "\n",
    "we'll use learning rate of 0.001 and freeze weights for the backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de392d655a630d3b73dfa84fe1febbed0f3fdbe2"
   },
   "outputs": [],
   "source": [
    "model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=b.retinanet,\n",
    "            num_classes=train_gen.num_classes(),\n",
    "            weights=None,\n",
    "            multi_gpu=False,\n",
    "            freeze_backbone=True,\n",
    "            lr=1e-3,\n",
    "            config=args.config\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a34e90ba8fec837af9007610241b487b9a6a807c"
   },
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    training_model,\n",
    "    prediction_model,\n",
    "    valid_gen,\n",
    "    args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33285a3b74dc8580797f86678e080cbfecd7c668"
   },
   "source": [
    "# Download pretrained model\n",
    "\n",
    "We download a pretrained model on COCO dataset and load it's weights, we'll skip loading the weights for the few last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "764a0430cc7c5f5f341bb3ba3bb89b699248481e"
   },
   "outputs": [],
   "source": [
    "#!wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "275ddf407b82092a0ec8a514500c0987f918d59b"
   },
   "outputs": [],
   "source": [
    "training_model.load_weights('./resnet50_coco_best_v2.1.0.h5',skip_mismatch=True,by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7cd58d21715eb0ec3a9de5b30be8cea85915726"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "We will train for total 30 epochs. When after few epochs, there is no significant improvement in the model we'll unfreeze the model by running above cells and resume the training <br/>\n",
    "Note: Do change the initial_epoch when resuming the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06bca3482f679c50640b7396bafb9b291b4f402b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_model.fit_generator(generator=augment_train_gen(train_gen),\n",
    "        steps_per_epoch=args.steps,\n",
    "        epochs=args.epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        workers=2,\n",
    "        use_multiprocessing=True,\n",
    "        shuffle=True,\n",
    "        initial_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a5b84c37c58444c37e6d08fb6de19b756c03926"
   },
   "outputs": [],
   "source": [
    "## training without augmentation to the dataset\n",
    "\n",
    "# model.fit_generator(generator=train_gen,\n",
    "#         steps_per_epoch=args.steps,\n",
    "#         epochs=args.epochs,\n",
    "#         verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "#         workers=2,\n",
    "#         use_multiprocessing=True,\n",
    "#         shuffle=True,\n",
    "#         initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Script\n",
    " To check if model is running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import timeit\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "#     random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
    "#     net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
    "#     net_cpu = tf.reduce_sum(net_cpu)\n",
    "\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
    "#     net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
    "#     net_gpu = tf.reduce_sum(net_gpu)\n",
    "\n",
    "# sess = tf.Session(config=config)\n",
    "\n",
    "# # Test execution once to detect errors early.\n",
    "# try:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "# except tf.errors.InvalidArgumentError:\n",
    "#     print(\n",
    "#       '\\n\\nThis error most likely means that this system is not '\n",
    "#       'configured to use a GPU. \\n\\n')\n",
    "#     raise\n",
    "\n",
    "# def cpu():\n",
    "#     sess.run(net_cpu)\n",
    "\n",
    "# def gpu():\n",
    "#     sess.run(net_gpu)\n",
    "\n",
    "# # Runs the op several times.\n",
    "# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "#       '(batch x height x width x channel). Sum of ten runs.')\n",
    "# print('CPU (s):')\n",
    "# cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "# print(cpu_time)\n",
    "# print('GPU (s):')\n",
    "# gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "# print(gpu_time)\n",
    "# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
    "\n",
    "# sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib \n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# #print(dir(tf.feature_column))\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
